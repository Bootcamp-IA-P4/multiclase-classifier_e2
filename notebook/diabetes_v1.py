# -*- coding: utf-8 -*-
"""diabetes_v1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zWKj7mQdPVmShcb3u21VG_boVR0I31D0
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# Configuración inicial
pd.set_option('display.max_columns', None)
plt.style.use('ggplot')

# Cargar los datos (asegúrate de tener el archivo en tu entorno)
df = pd.read_csv('../data/diabetes_012_health_indicators.csv')

## 1. Primer vistazo a los datos
print("="*80)
print("1. PRIMER VISTAZO A LOS DATOS")
print("="*80)

# Dimensiones del dataset
print(f"\nDimensiones del dataset: {df.shape}")

# Primeras filas
print("\nPrimeras 5 filas:")
display(df.head())

# Información de tipos de datos y nulos
print("\nInformación de tipos de datos y nulos:")
print(df.info())

# Estadísticas descriptivas
print("\nEstadísticas descriptivas:")
display(df.describe().T)

## 2. Análisis de la variable objetivo (Diabetes_012)
print("\n" + "="*80)
print("2. ANÁLISIS DE LA VARIABLE OBJETIVO (Diabetes_012)")
print("="*80)

# Distribución de clases
diabetes_dist = df['Diabetes_012'].value_counts(normalize=True) * 100
print("\nDistribución de clases (%):")
display(diabetes_dist)

# Mapeo de valores para mejor visualización
diabetes_labels = {0: 'No diabetes', 1: 'Prediabetes', 2: 'Diabetes'}

# Gráfico de distribución
plt.figure(figsize=(10, 6))
ax = sns.countplot(x='Diabetes_012', data=df, palette='viridis')
ax.set_xticklabels([diabetes_labels[i] for i in sorted(df['Diabetes_012'].unique())])
plt.title('Distribución de la Variable Objetivo (Diabetes_012)')
plt.xlabel('Estado de Diabetes')
plt.ylabel('Cantidad')
for p in ax.patches:
    ax.annotate(f'{p.get_height():,}', (p.get_x()+p.get_width()/2., p.get_height()),
                ha='center', va='center', xytext=(0, 10), textcoords='offset points')
plt.show()

## 3. Análisis de variables numéricas
print("\n" + "="*80)
print("3. ANÁLISIS DE VARIABLES NUMÉRICAS")
print("="*80)

# Seleccionar variables numéricas
numeric_vars = ['BMI', 'MentHlth', 'PhysHlth', 'Age', 'Education', 'Income']

# Histogramas
print("\nHistogramas de variables numéricas:")
plt.figure(figsize=(15, 10))
for i, var in enumerate(numeric_vars, 1):
    plt.subplot(2, 3, i)
    sns.histplot(data=df, x=var, kde=True, bins=30)
    plt.title(f'Distribución de {var}')
plt.tight_layout()
plt.show()

# Boxplots por categoría de diabetes
print("\nBoxplots por categoría de diabetes:")
plt.figure(figsize=(15, 10))
for i, var in enumerate(numeric_vars, 1):
    plt.subplot(2, 3, i)
    sns.boxplot(x='Diabetes_012', y=var, data=df, palette='viridis')
    plt.title(f'{var} por categoría de diabetes')
    plt.xlabel('Estado de Diabetes')
    plt.xticks(ticks=[0, 1, 2], labels=[diabetes_labels[i] for i in [0, 1, 2]])
plt.tight_layout()
plt.show()

## 4. Análisis de variables categóricas
print("\n" + "="*80)
print("4. ANÁLISIS DE VARIABLES CATEGÓRICAS")
print("="*80)

# Seleccionar variables categóricas binarias
binary_vars = ['HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke',
               'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',
               'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'DiffWalk', 'Sex']

# Gráficos de barras para cada variable categórica vs diabetes
print("\nDistribución de variables categóricas por estado de diabetes:")
plt.figure(figsize=(20, 30))
for i, var in enumerate(binary_vars, 1):
    plt.subplot(5, 3, i)
    sns.countplot(x=var, hue='Diabetes_012', data=df, palette='viridis')
    plt.title(f'{var} por estado de diabetes')
    plt.xlabel(var)
    plt.ylabel('Cantidad')
    plt.legend(title='Diabetes', labels=[diabetes_labels[i] for i in [0, 1, 2]])
plt.tight_layout()
plt.show()

## 5. Análisis de correlaciones
print("\n" + "="*80)
print("5. ANÁLISIS DE CORRELACIONES")
print("="*80)

# Matriz de correlación
corr_matrix = df.corr()

# Heatmap de correlaciones
plt.figure(figsize=(20, 15))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm',
            center=0, linewidths=0.5, annot_kws={"size": 8})
plt.title('Matriz de Correlación entre Variables')
plt.show()

# Correlaciones con la variable objetivo
print("\nCorrelaciones con Diabetes_012:")
display(corr_matrix['Diabetes_012'].sort_values(ascending=False))

## 6. Análisis de valores atípicos
print("\n" + "="*80)
print("6. ANÁLISIS DE VALORES ATÍPICOS")
print("="*80)

# Boxplots para detectar outliers en variables numéricas
print("\nDetección de outliers en variables numéricas:")
plt.figure(figsize=(15, 8))
for i, var in enumerate(numeric_vars, 1):
    plt.subplot(2, 3, i)
    sns.boxplot(y=df[var], color='skyblue')
    plt.title(f'Boxplot de {var}')
plt.tight_layout()
plt.show()

# Cálculo de outliers usando el método IQR
print("\nConteo de outliers por variable numérica (método IQR):")
outliers_count = {}
for var in numeric_vars:
    Q1 = df[var].quantile(0.25)
    Q3 = df[var].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = df[(df[var] < lower_bound) | (df[var] > upper_bound)]
    outliers_count[var] = outliers.shape[0]

outliers_df = pd.DataFrame.from_dict(outliers_count, orient='index', columns=['Outliers Count'])
display(outliers_df)

## 7. Análisis de relaciones entre variables clave
print("\n" + "="*80)
print("7. ANÁLISIS DE RELACIONES ENTRE VARIABLES CLAVE")
print("="*80)

# Relación entre BMI y Diabetes
plt.figure(figsize=(12, 6))
sns.violinplot(x='Diabetes_012', y='BMI', data=df, palette='viridis')
plt.title('Distribución de BMI por Estado de Diabetes')
plt.xlabel('Estado de Diabetes')
plt.xticks(ticks=[0, 1, 2], labels=[diabetes_labels[i] for i in [0, 1, 2]])
plt.ylabel('BMI')
plt.show()

# Relación entre Edad y Diabetes
plt.figure(figsize=(12, 6))
sns.countplot(x='Age', hue='Diabetes_012', data=df, palette='viridis')
plt.title('Distribución de Edad por Estado de Diabetes')
plt.xlabel('Categoría de Edad')
plt.ylabel('Cantidad')
plt.legend(title='Diabetes', labels=[diabetes_labels[i] for i in [0, 1, 2]])
plt.show()

# Relación entre Salud General y Diabetes
plt.figure(figsize=(12, 6))
sns.countplot(x='GenHlth', hue='Diabetes_012', data=df, palette='viridis')
plt.title('Salud General por Estado de Diabetes')
plt.xlabel('Salud General (1=Excelente, 5=Pobre)')
plt.ylabel('Cantidad')
plt.legend(title='Diabetes', labels=[diabetes_labels[i] for i in [0, 1, 2]])
plt.show()

# Verificar duplicados

duplicados = df.duplicated().sum()

print(f"\nNúmero de filas duplicadas: {duplicados}")

# Contar duplicados exactos (todas las columnas)
duplicados_exactos = df.duplicated(keep=False)
print("Número de filas duplicadas exactas:", duplicados_exactos.sum())

# Ver algunas filas duplicadas
df[duplicados_exactos].sort_values(by=df.columns.tolist()).head(10)

# Contar filas duplicadas exactas (todas las columnas)
duplicados_conteo = df.value_counts().reset_index(name='count')

# Mostrar combinaciones que se repiten más de una vez
duplicados_reales = duplicados_conteo[duplicados_conteo['count'] > 1]
print("Número de combinaciones de datos que se repiten:", len(duplicados_reales))

# Ver ejemplos
duplicados_reales.sort_values(by='count', ascending=False).head(10)

# Añadir columna para contar duplicados por clase
duplicados_por_clase = df[df.duplicated(keep=False)].groupby('Diabetes_012').size()
print(duplicados_por_clase)

from sklearn.utils import shuffle

# Mezclar los datos primero para evitar sesgos en el orden
df_shuffled = shuffle(df, random_state=42)

# Eliminar duplicados pero priorizando mantener casos de clases minoritarias
df_cleaned = df_shuffled.sort_values('Diabetes_012').drop_duplicates(keep='first')

# Verificar resultados
duplicates_removed = len(df) - len(df_cleaned)
print(f"\nSe eliminaron {duplicates_removed} registros duplicados")
print("Nueva distribución:")
print(df_cleaned['Diabetes_012'].value_counts())

# Comprobación rápida de distribuciones
print("\nDistribución de variables clave después de limpieza:")
for var in ['HighBP', 'HighChol', 'BMI', 'GenHlth']:
    print(f"\n{var} por clase:")
    print(df_cleaned.groupby('Diabetes_012')[var].describe())

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Separar features y target
X = df_cleaned.drop('Diabetes_012', axis=1)
y = df_cleaned['Diabetes_012']

# División train-test (estratificada)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

# Escalado numérico (aplicar solo a variables continuas)
numeric_vars = ['BMI', 'MentHlth', 'PhysHlth', 'Age']
scaler = StandardScaler()
X_train[numeric_vars] = scaler.fit_transform(X_train[numeric_vars])
X_test[numeric_vars] = scaler.transform(X_test[numeric_vars])

from imblearn.combine import SMOTETomek
from imblearn.under_sampling import TomekLinks

smt = SMOTETomek(
    sampling_strategy={1: 15000, 2: 50000},  # Ajustar según necesidad
    random_state=42,
    tomek=TomekLinks(sampling_strategy='majority')
)

X_res, y_res = smt.fit_resample(X_train, y_train)

# Verificación final
print("\nDistribución después de balanceo:")
print(pd.Series(y_res).value_counts())

from xgboost import XGBClassifier
from sklearn.metrics import classification_report

# Modelo con pesos ajustados
model = XGBClassifier(
    objective='multi:softmax',
    num_class=3,
    scale_pos_weight=[sum(y_res==0)/sum(y_res==1), sum(y_res==0)/sum(y_res==2)],  # Pesos automáticos
    n_estimators=300,
    max_depth=6,
    learning_rate=0.05,
    subsample=0.8,
    colsample_bytree=0.8,
    reg_alpha=0.5,
    reg_lambda=0.5,
    random_state=42
)

# Entrenamiento
model.fit(X_res, y_res)

# Evaluación
y_pred = model.predict(X_test)
print("\nEvaluación Final:")
print(classification_report(y_test, y_pred, target_names=['No diabetes', 'Prediabetes', 'Diabetes']))

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Matriz de confusión normalizada
cm = confusion_matrix(y_test, y_pred, normalize='true')
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                            display_labels=['No diabetes', 'Prediabetes', 'Diabetes'])
disp.plot(cmap='Blues')
plt.title("Matriz de Confusión Normalizada")
plt.show()

# Importancia de características
plt.figure(figsize=(10, 8))
sorted_idx = model.feature_importances_.argsort()
plt.barh(X.columns[sorted_idx], model.feature_importances_[sorted_idx])
plt.title("Importancia de Características (XGBoost)")
plt.show()

from imblearn.over_sampling import ADASYN

# Enfoque más agresivo para prediabetes
adasyn = ADASYN(sampling_strategy={1: 30000, 2: 60000}, random_state=42)
X_res, y_res = adasyn.fit_resample(X_train, y_train)

# Verificar nueva distribución
print(pd.Series(y_res).value_counts())

from lightgbm import LGBMClassifier

lgbm = LGBMClassifier(
    objective='multiclass',
    class_weight='balanced',
    n_estimators=500,
    learning_rate=0.05,
    num_leaves=31,
    reg_alpha=0.5,
    reg_lambda=0.5,
    random_state=42
)

lgbm.fit(X_res, y_res)

# Obtener probabilidades en lugar de predicciones directas
y_probs = model.predict_proba(X_test)

# Ajustar umbrales para clases minoritarias
new_thresholds = [0.7, 0.15, 0.15]  # [No diabetes, Prediabetes, Diabetes]
y_pred_adj = np.argmax(y_probs / new_thresholds, axis=1)

# Re-evaluar
print(classification_report(y_test, y_pred_adj))

from imblearn.combine import SMOTETomek
from imblearn.under_sampling import TomekLinks

smt = SMOTETomek(
    sampling_strategy={1: 15000, 2: 50000},  # Ajustar según necesidad
    random_state=42,
    tomek=TomekLinks(sampling_strategy='majority')
)

X_res, y_res = smt.fit_resample(X_train, y_train)

# Verificación final
print("\nDistribución después de balanceo:")
print(pd.Series(y_res).value_counts())

# Crear variables de interacción clave
df['MetabolicSyndrome'] = (df['HighBP'] + df['HighChol'] + (df['BMI'] > 30)).astype(int)
df['Age_Health_Risk'] = df['Age'] * df['GenHlth']
df['Lifestyle_Score'] = df['PhysActivity'] - df['HvyAlcoholConsump'] + df['Fruits']

from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.base import BaseEstimator, ClassifierMixin
import numpy as np

class HierarchicalDiabetesClassifier(BaseEstimator, ClassifierMixin):
    def __init__(self):
        self.binary_model = XGBClassifier(
            objective='binary:logistic',
            scale_pos_weight=5,  # Ajustar según tus datos
            random_state=42
        )
        self.secondary_model = None  # Se inicializará en el fit

    def fit(self, X, y):
        # Paso 1: Modelo binario (0 vs 1+2)
        y_binary = np.where(y == 0, 0, 1)
        self.binary_model.fit(X, y_binary)

        # Paso 2: Modelo secundario (1 vs 2)
        risk_mask = y_binary == 1
        X_risk = X[risk_mask]
        y_risk = y[risk_mask]

        # Verificar que tenemos ambas clases y suficientes muestras
        unique_classes = np.unique(y_risk)
        if len(unique_classes) >= 2:
            self.secondary_model = LGBMClassifier(
                objective='multiclass',
                num_class=len(unique_classes),  # ¡Esto es crucial!
                class_weight='balanced',
                random_state=42
            )
            self.secondary_model.fit(X_risk, y_risk)
        else:
            raise ValueError(f"Datos insuficientes para modelo secundario. Clases encontradas: {unique_classes}")

        return self

    def predict(self, X):
        # Primera clasificación binaria
        binary_pred = self.binary_model.predict(X)

        # Inicializar predicciones finales
        final_pred = np.zeros(len(X), dtype=int)

        # Clasificación secundaria solo para casos de riesgo
        risk_mask = binary_pred == 1
        if sum(risk_mask) > 0 and self.secondary_model is not None:
            final_pred[risk_mask] = self.secondary_model.predict(X[risk_mask])

        return final_pred

# Uso correcto:
hierarchical_model = HierarchicalDiabetesClassifier()

# Asegúrate que X_train sea un DataFrame de pandas y y_train un array numpy
X_train_df = pd.DataFrame(X_train) if not isinstance(X_train, pd.DataFrame) else X_train
y_train_array = y_train.values if hasattr(y_train, 'values') else np.array(y_train)

hierarchical_model.fit(X_train_df, y_train_array)

# Predecir
X_test_df = pd.DataFrame(X_test) if not isinstance(X_test, pd.DataFrame) else X_test
y_pred = hierarchical_model.predict(X_test_df)

from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Generar predicciones
y_pred = hierarchical_model.predict(X_test_df)

# 1. Reporte de clasificación completo (usando labels numéricos)
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=['No diabetes', 'Prediabetes', 'Diabetes'], digits=3))

# 2. Matriz de confusión normalizada
cm = confusion_matrix(y_test, y_pred, normalize='true')
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No diabetes', 'Prediabetes', 'Diabetes'])
disp.plot(cmap='Blues', values_format='.2f')
plt.title("Matriz de Confusión Normalizada")
plt.show()

# 3. Métricas específicas para clases minoritarias (versión corregida)
print("\nMétricas Específicas:")
report = classification_report(y_test, y_pred, output_dict=True, target_names=['No diabetes', 'Prediabetes', 'Diabetes'])
print(f"Recall Prediabetes: {report['Prediabetes']['recall']:.3f}")  # Usar nombre de clase
print(f"Recall Diabetes: {report['Diabetes']['recall']:.3f}")
print(f"Precisión Diabetes: {report['Diabetes']['precision']:.3f}")

# Obtener probabilidades del modelo binario
y_binary_proba = hierarchical_model.binary_model.predict_proba(X_test_df)[:, 1]  # Probabilidad de ser caso de riesgo

# Experimentar con diferentes umbrales
for threshold in [0.3, 0.4, 0.5, 0.6]:
    binary_pred_adj = (y_binary_proba > threshold).astype(int)
    risk_mask = binary_pred_adj == 1

    print(f"\nUmbral: {threshold}")
    print(f"Casos identificados como riesgo: {sum(risk_mask)}/{len(risk_mask)} ({sum(risk_mask)/len(risk_mask):.1%})")

from imblearn.over_sampling import SMOTE

# Aplicar SMOTE solo al conjunto de riesgo
X_risk = X_train_df[hierarchical_model.binary_model.predict(X_train_df) == 1]
y_risk = y_train_array[hierarchical_model.binary_model.predict(X_train_df) == 1]

smote = SMOTE(sampling_strategy={1: 5000, 2: 10000}, random_state=42)
X_risk_res, y_risk_res = smote.fit_resample(X_risk, y_risk)

# Reentrenar solo el modelo secundario
hierarchical_model.secondary_model = LGBMClassifier(
    objective='multiclass',
    num_class=3,
    class_weight='balanced',
    n_estimators=300,
    random_state=42
).fit(X_risk_res, y_risk_res)

from collections import Counter
print("Distribución en y_risk:", Counter(y_risk))

from imblearn.over_sampling import SMOTE
from collections import Counter
from lightgbm import LGBMClassifier

# Paso 1: Casos positivos del modelo binario
X_risk = X_train_df[hierarchical_model.binary_model.predict(X_train_df) == 1]
y_risk = y_train_array[hierarchical_model.binary_model.predict(X_train_df) == 1]

# Paso 2: Filtrar solo clases 1 (Prediabetes) y 2 (Diabetes)
mask_pos = (y_risk == 1.0) | (y_risk == 2.0)
X_risk_filtered = X_risk[mask_pos]
y_risk_filtered = y_risk[mask_pos]

# Paso 3: Aplicar SMOTE para balancear automáticamente
print("Distribución antes de SMOTE:", Counter(y_risk_filtered))
smote = SMOTE(sampling_strategy='auto', random_state=42)
X_risk_res, y_risk_res = smote.fit_resample(X_risk_filtered, y_risk_filtered)
print("Distribución después de SMOTE:", Counter(y_risk_res))

# Paso 4: Reentrenar el modelo secundario (Prediabetes vs Diabetes)
hierarchical_model.secondary_model = LGBMClassifier(
    objective='multiclass',
    num_class=2,
    class_weight='balanced',
    n_estimators=300,
    random_state=42
).fit(X_risk_res, y_risk_res)

from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score, roc_auc_score
from sklearn.preprocessing import label_binarize
import numpy as np

# Paso 1: Predicciones del modelo binario
y_pred_primary = hierarchical_model.binary_model.predict(X_test_df)

# Paso 2: Aplicar solo a casos positivos
X_test_positive = X_test_df[y_pred_primary == 1]
y_test_positive = y_test[y_pred_primary == 1]

# Validar clases
print("Clases presentes en test positivo:", np.unique(y_test_positive))

# Paso 3: Predicciones y probabilidades del modelo secundario
y_pred_secondary = hierarchical_model.secondary_model.predict(X_test_positive)
y_probs_secondary = hierarchical_model.secondary_model.predict_proba(X_test_positive)

# Paso 4: Métricas
print("Balanced Accuracy:", balanced_accuracy_score(y_test_positive, y_pred_secondary))
print("Cohen's Kappa:", cohen_kappa_score(y_test_positive, y_pred_secondary))

# ROC AUC (con binarización)
y_test_bin = label_binarize(y_test_positive, classes=[1.0, 2.0])
roc_auc_prediabetes = roc_auc_score(y_test_bin[:, 0], y_probs_secondary[:, 0])
roc_auc_diabetes = roc_auc_score(y_test_bin[:, 1], y_probs_secondary[:, 1])

print("ROC AUC (Prediabetes):", roc_auc_prediabetes)
print("ROC AUC (Diabetes):", roc_auc_diabetes)

from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score, roc_auc_score
from sklearn.preprocessing import label_binarize
import numpy as np

# Paso 1: Predicciones del modelo binario
y_pred_primary = hierarchical_model.binary_model.predict(X_test_df)

# Paso 2: Seleccionar donde el binario predice 1 (en riesgo)
risk_mask = y_pred_primary == 1

# Pero además filtramos etiquetas verdaderas: deben ser 1 o 2 (sin clase 0)
valid_classes_mask = (y_test == 1.0) | (y_test == 2.0)

# Máscara conjunta para asegurar evaluación limpia
final_mask = risk_mask & valid_classes_mask

# Datos definitivos para evaluar el modelo secundario
X_test_secondary = X_test_df[final_mask]
y_test_secondary = y_test[final_mask]

# Predicción y probas
y_pred_secondary = hierarchical_model.secondary_model.predict(X_test_secondary)
y_probs_secondary = hierarchical_model.secondary_model.predict_proba(X_test_secondary)

# Evaluación
print("Clases presentes en y_test_secondary:", np.unique(y_test_secondary))
print("Balanced Accuracy:", balanced_accuracy_score(y_test_secondary, y_pred_secondary))
print("Cohen's Kappa:", cohen_kappa_score(y_test_secondary, y_pred_secondary))

# ROC AUC (solo si hay ambas clases presentes)
unique_classes = np.unique(y_test_secondary)
y_test_bin = label_binarize(y_test_secondary, classes=[1.0, 2.0])

if len(unique_classes) == 2 and y_probs_secondary.shape[1] == 2:
	print("ROC AUC (Prediabetes):", roc_auc_score(y_test_bin[:, 0], y_probs_secondary[:, 0]))
	print("ROC AUC (Diabetes):", roc_auc_score(y_test_bin[:, 1], y_probs_secondary[:, 1]))
elif len(unique_classes) == 1 and y_probs_secondary.shape[1] == 1:
	print(f"⚠️ Solo hay una clase presente en y_test_secondary: {unique_classes[0]}. No se puede calcular ROC AUC binario.")
elif y_probs_secondary.shape[1] == 1:
	# Solo una clase fue predicha por el modelo secundario
	print("⚠️ El modelo solo predice una clase. No se puede calcular ROC AUC binario.")
elif len(unique_classes) == 1 and y_probs_secondary.shape[1] == 2:
	# Dos columnas pero solo una clase verdadera (raro pero posible)
	idx = int(unique_classes[0] - 1)  # 1->0, 2->1
	print(f"⚠️ Solo hay una clase verdadera ({unique_classes[0]}). ROC AUC solo para esa clase:")
	print(f"ROC AUC (clase {int(unique_classes[0])}):", roc_auc_score(y_test_bin[:, idx], y_probs_secondary[:, idx]))
else:
	print("⚠️ No se puede calcular ROC AUC binario. Clases insuficientes o modelo mal entrenado.")

"""---------------------------------------------------"""

from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer

# Tratamiento de outliers
for var in ['BMI', 'MentHlth', 'PhysHlth']:
    df[var] = np.where(df[var] > df[var].quantile(0.99), df[var].quantile(0.99), df[var])

# Transformación de variables
numeric_vars = ['BMI', 'MentHlth', 'PhysHlth', 'Age']
categorical_vars = ['HighBP', 'HighChol', 'GenHlth', 'DiffWalk']

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_vars),
        ('cat', OneHotEncoder(drop='first'), categorical_vars)
    ])

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split

# Cargar datos (asegúrate de tener el DataFrame `df`)
# df = pd.read_csv('diabetes_012_health_indicators_BRFSS2015.csv')

### **1.1. Creación de nuevas variables (Feature Engineering)**
# Variable combinada: Riesgo Metabólico (HighBP + HighChol + BMI > 30)
df['MetabolicRisk'] = df['HighBP'] + df['HighChol'] + (df['BMI'] > 30).astype(int)

# Discretizar Age en grupos etarios
age_bins = [0, 4, 8, 12, 13]
age_labels = ['18-44', '45-64', '65-79', '80+']
df['AgeGroup'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels)

# Indicador de Salud General Pobre (GenHlth >= 4)
df['PoorHealth'] = (df['GenHlth'] >= 4).astype(int)

# Variable de Estilo de Vida Saludable (PhysActivity + Fruits + Veggies)
df['HealthyLifestyle'] = df['PhysActivity'] + df['Fruits'] + df['Veggies']

# Mostrar nuevas variables
print("\nNuevas variables creadas:")
print(df[['MetabolicRisk', 'AgeGroup', 'PoorHealth', 'HealthyLifestyle']].head())

### **2.1. Tratamiento de Outliers (Winsorización)**
for var in ['BMI', 'MentHlth', 'PhysHlth']:
    upper_limit = df[var].quantile(0.99)
    df[var] = np.where(df[var] > upper_limit, upper_limit, df[var])

print("\nOutliers tratados en BMI, MentHlth y PhysHlth.")

### **2.2. Definición de Variables Predictoras (X) y Objetivo (y)**
X = df.drop(columns=['Diabetes_012'])  # Todas las variables excepto la objetivo
y = df['Diabetes_012']  # Variable objetivo multiclase (0, 1, 2)

### **2.3. Codificación y Escalado**
# Variables numéricas y categóricas
numeric_vars = ['BMI', 'MentHlth', 'PhysHlth', 'Age', 'MetabolicRisk', 'HealthyLifestyle']
categorical_vars = ['HighBP', 'HighChol', 'GenHlth', 'DiffWalk', 'AgeGroup', 'PoorHealth']

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_vars),
        ('cat', OneHotEncoder(drop='first'), categorical_vars)
    ])

# Aplicar transformaciones
X_processed = preprocessor.fit_transform(X)

print("\nPreprocesamiento completado. Dimensiones de X_processed:", X_processed.shape)

### **3.1. División en Train y Test (antes de balancear)**
X_train, X_test, y_train, y_test = train_test_split(
    X_processed, y, test_size=0.3, random_state=42, stratify=y
)

print("\nDistribución original en y_train:")
print(y_train.value_counts(normalize=True) * 100)

### **3.2. Aplicar SMOTE solo al conjunto de entrenamiento**
smote = SMOTE(sampling_strategy={1: 20000, 2: 50000}, random_state=42)
X_res, y_res = smote.fit_resample(X_train, y_train)

print("\nDistribución después de SMOTE:")
print(pd.Series(y_res).value_counts(normalize=True) * 100)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay

# Entrenar modelo inicial
model_rf = RandomForestClassifier(class_weight='balanced', random_state=42)
model_rf.fit(X_res, y_res)

# Predecir en el conjunto de prueba
y_pred = model_rf.predict(X_test)

# Métricas de evaluación
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=['No diabetes', 'Prediabetes', 'Diabetes']))

# Matriz de confusión
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No diabetes', 'Prediabetes', 'Diabetes'])
disp.plot(cmap='Blues')
plt.title("Matriz de Confusión - Random Forest")
plt.show()

from imblearn.over_sampling import ADASYN
from imblearn.under_sampling import TomekLinks
from imblearn.pipeline import make_pipeline

# Combinación de oversampling y undersampling
adasyn = ADASYN(sampling_strategy={1: 30000, 2: 60000}, random_state=42)
tomek = TomekLinks(sampling_strategy='majority')

# Pipeline integrado
pipeline = make_pipeline(adasyn, tomek, RandomForestClassifier(class_weight='balanced'))
pipeline.fit(X_train, y_train)

# Crear variables de interacción clave
df['BP_Chol_interaction'] = df['HighBP'] * df['HighChol']
df['BMI_Age_interaction'] = df['BMI'] * df['Age']
df['Health_Risk'] = df['GenHlth'] * df['PoorHealth']

# Transformación polinómica para variables numéricas
df['BMI_squared'] = df['BMI']**2
df['Age_squared'] = df['Age']**2

from sklearn.ensemble import GradientBoostingClassifier
from imblearn.ensemble import BalancedBaggingClassifier

# Opción 1: Gradient Boosting con focal loss (manejo de clases desbalanceadas)
gb_model = GradientBoostingClassifier(loss='deviance', n_estimators=200,
                                    max_depth=5, learning_rate=0.1)

# Opción 2: Ensemble balanceado
bbc = BalancedBaggingClassifier(base_estimator=RandomForestClassifier(),
                              sampling_strategy='auto',
                              replacement=False,
                              random_state=42)

from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
from imblearn.ensemble import BalancedBaggingClassifier

# Opción 1: Gradient Boosting (Nota: 'deviance' es la pérdida por defecto para clasificación)
gb_model = GradientBoostingClassifier(loss='log_loss',  # Cambiado a 'log_loss' que es más estándar
                                    n_estimators=200,
                                    max_depth=5,
                                    learning_rate=0.1,
                                    random_state=42)

# Opción 2: Ensemble balanceado CORREGIDO
bbc = BalancedBaggingClassifier(estimator=RandomForestClassifier(),  # Cambiado de base_estimator a estimator
                              sampling_strategy='auto',
                              replacement=False,
                              random_state=42)

import imblearn
print(imblearn.__version__)

# Primero modelo binario: Diabetes (1) vs No Diabetes (0)
# Luego modelo secundario para Prediabetes vs Diabetes

from sklearn.multiclass import OneVsRestClassifier

# Convertir a problema binario primero
y_binary = y_train.where(y_train == 0, 1)  # 0 = No diabetes, 1 = Prediabetes/Diabetes

# Entrenar modelo binario
binary_model = RandomForestClassifier().fit(X_train, y_binary)

# Luego modelo para distinguir Prediabetes vs Diabetes en los casos positivos
mask = y_train > 0
X_positive = X_train[mask]
y_positive = y_train[mask]

secondary_model = RandomForestClassifier().fit(X_positive, y_positive)

from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score, roc_auc_score

# Primero: Evaluación del modelo binario
y_pred_binary = binary_model.predict(X_test)
binary_test = y_test.where(y_test == 0, 1)  # Convertir y_test a binario

print("\nEvaluación del Modelo Binario:")
print("Balanced Accuracy:", balanced_accuracy_score(binary_test, y_pred_binary))
print("Cohen's Kappa:", cohen_kappa_score(binary_test, y_pred_binary))
print("ROC AUC:", roc_auc_score(binary_test, binary_model.predict_proba(X_test)[:, 1]))

# Segundo: Evaluación del modelo secundario (solo en casos positivos)
positive_mask = y_test > 0
X_test_positive = X_test[positive_mask]
y_test_positive = y_test[positive_mask]

if len(X_test_positive) > 0:  # Solo si hay casos positivos en el test
    y_pred_secondary = secondary_model.predict(X_test_positive)

    print("\nEvaluación del Modelo Secundario (Prediabetes vs Diabetes):")
    print("Balanced Accuracy:", balanced_accuracy_score(y_test_positive, y_pred_secondary))
    print("Cohen's Kappa:", cohen_kappa_score(y_test_positive, y_pred_secondary))

    # ROC AUC para multiclase (2 clases en este caso)
    try:
        print("ROC AUC OvO:", roc_auc_score(y_test_positive,
                                          secondary_model.predict_proba(X_test_positive),
                                          multi_class='ovo'))
    except Exception as e:
        print("Error en ROC AUC:", str(e))
else:
    print("\nNo hay casos positivos en el conjunto de prueba para evaluar el modelo secundario.")

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

clf = RandomForestClassifier(random_state=42)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))

# Corrección para el modelo secundario
if len(X_test_positive) > 0:
    y_probs_secondary = secondary_model.predict_proba(X_test_positive)

    # Para ROC AUC en multiclase necesitamos binarizar las etiquetas
    from sklearn.preprocessing import label_binarize
    y_test_bin = label_binarize(y_test_positive, classes=[1, 2])

    print("ROC AUC (clase Prediabetes):", roc_auc_score(y_test_bin[:, 0], y_probs_secondary[:, 0]))
    print("ROC AUC (clase Diabetes):", roc_auc_score(y_test_bin[:, 1], y_probs_secondary[:, 1]))

print("Clases en y_positive:", y_positive.unique())

from collections import Counter
print(Counter(y_positive))

from imblearn.over_sampling import ADASYN
from sklearn.ensemble import RandomForestClassifier

# Balancear clases 1 y 2 antes de entrenar el modelo secundario
adasyn = ADASYN(sampling_strategy='auto', random_state=42)
X_resampled, y_resampled = adasyn.fit_resample(X_positive, y_positive)

# Entrenar el modelo balanceado
secondary_model = RandomForestClassifier(random_state=42)
secondary_model.fit(X_resampled, y_resampled)

from sklearn.preprocessing import label_binarize

y_pred_secondary = secondary_model.predict(X_test_positive)
y_probs_secondary = secondary_model.predict_proba(X_test_positive)

# Verifica si hay ambas clases en y_test_positive
if len(np.unique(y_test_positive)) == 2:
    y_test_bin = label_binarize(y_test_positive, classes=[1, 2])

    print("Balanced Accuracy:", balanced_accuracy_score(y_test_positive, y_pred_secondary))
    print("Cohen's Kappa:", cohen_kappa_score(y_test_positive, y_pred_secondary))
    print("ROC AUC (Prediabetes):", roc_auc_score(y_test_bin[:, 0], y_probs_secondary[:, 0]))
    print("ROC AUC (Diabetes):", roc_auc_score(y_test_bin[:, 1], y_probs_secondary[:, 1]))
else:
    print("No hay suficientes clases para calcular ROC AUC binario.")

import numpy as np
print("Clases presentes en y_test_positive:", np.unique(y_test_positive))
print("Shape de y_probs_secondary:", y_probs_secondary.shape)

from sklearn.preprocessing import label_binarize

# Verificamos número de clases y shape de salida
y_probs_secondary = secondary_model.predict_proba(X_test_positive)
unique_classes = np.unique(y_test_positive)

print("Clases presentes en test:", unique_classes)
print("Shape de predict_proba:", y_probs_secondary.shape)

if len(unique_classes) == 2 and y_probs_secondary.shape[1] == 2:
    y_test_bin = label_binarize(y_test_positive, classes=[1, 2])

    print("Balanced Accuracy:", balanced_accuracy_score(y_test_positive, y_pred_secondary))
    print("Cohen's Kappa:", cohen_kappa_score(y_test_positive, y_pred_secondary))
    print("ROC AUC (Prediabetes):", roc_auc_score(y_test_bin[:, 0], y_probs_secondary[:, 0]))
    print("ROC AUC (Diabetes):", roc_auc_score(y_test_bin[:, 1], y_probs_secondary[:, 1]))
else:
    print("⚠️ No se puede calcular ROC AUC binario. Clases insuficientes o modelo mal entrenado.")

from sklearn.preprocessing import MultiLabelBinarizer

mlb = MultiLabelBinarizer(classes=[1, 2])
y_test_bin = mlb.fit_transform(y_test_positive.values.reshape(-1, 1))

print("y_test_bin shape:", y_test_bin.shape)
print("Balanced Accuracy:", balanced_accuracy_score(y_test_positive, y_pred_secondary))
print("Cohen's Kappa:", cohen_kappa_score(y_test_positive, y_pred_secondary))
print("ROC AUC (Prediabetes):", roc_auc_score(y_test_bin[:, 0], y_probs_secondary[:, 0]))
print("ROC AUC (Diabetes):", roc_auc_score(y_test_bin[:, 1], y_probs_secondary[:, 1]))